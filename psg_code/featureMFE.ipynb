{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StartDate  duration  hy\n",
      "0  12:43:06     18.49  hy\n",
      "1  12:44:55     13.36  hy\n",
      "2  12:46:27     10.55  hy\n",
      "3  12:46:41     10.60  hy\n",
      "4  12:46:56     10.80  hy\n",
      "            StartDate  duration  hy                 endDate\n",
      "0 1900-01-01 12:43:06     18.49  hy 1900-01-01 12:43:24.490\n",
      "1 1900-01-01 12:44:55     13.36  hy 1900-01-01 12:45:08.360\n",
      "2 1900-01-01 12:46:27     10.55  hy 1900-01-01 12:46:37.550\n",
      "3 1900-01-01 12:46:41     10.60  hy 1900-01-01 12:46:51.600\n",
      "4 1900-01-01 12:46:56     10.80  hy 1900-01-01 12:47:06.800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến tệp Excel\n",
    "file_path = './input/label.xlsx'\n",
    "\n",
    "# Đọc tệp Excel\n",
    "datatimeOA = pd.read_excel(file_path)\n",
    "\n",
    "# Hiển thị các dòng đầu tiên của DataFrame\n",
    "print(datatimeOA.head())\n",
    "datatimeOA['StartDate'] = pd.to_datetime(datatimeOA['StartDate'], format='%H:%M:%S')\n",
    "\n",
    "# Tính toán endDate bằng cách thêm duration (tính bằng giờ) vào StartDate\n",
    "datatimeOA['endDate'] = datatimeOA['StartDate'] + pd.to_timedelta(datatimeOA['duration'], unit='s')\n",
    "\n",
    "# Hiển thị các dòng đầu tiên của DataFrame sau khi tính toán\n",
    "print(datatimeOA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatimeOA['endDate'] = pd.to_datetime(datatimeOA['endDate'], format='%H:%M:%S:%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           time       value\n",
      "0  00:37:06:186  106.784265\n",
      "1  00:37:06:196  104.678488\n",
      "2  00:37:06:206  103.732414\n",
      "3  00:37:06:216  101.779229\n",
      "4  00:37:06:226  100.894192\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến tệp Excel\n",
    "file_path = './input/audio.xlsx'\n",
    "\n",
    "# Đọc tệp Excel\n",
    "flowData = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Hiển thị các dòng đầu tiên của DataFrame\n",
    "print(flowData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hour_to_12(dt):\n",
    "    if dt.hour == 0:\n",
    "        return dt.replace(hour=12)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time       value  nhan\n",
      "0 1900-01-01 12:37:06.186  106.784265     0\n",
      "1 1900-01-01 12:37:06.196  104.678488     0\n",
      "2 1900-01-01 12:37:06.206  103.732414     0\n",
      "3 1900-01-01 12:37:06.216  101.779229     0\n",
      "4 1900-01-01 12:37:06.226  100.894192     0\n"
     ]
    }
   ],
   "source": [
    "flowData['time'] = pd.to_datetime(flowData['time'], format='%H:%M:%S:%f')\n",
    "flowData['time'] = flowData['time'].apply(convert_hour_to_12)\n",
    "flowData['nhan'] = 0\n",
    "print(flowData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time       value  nhan\n",
      "0 1900-01-01 12:37:06.186  106.784265     0\n",
      "1 1900-01-01 12:37:06.196  104.678488     0\n",
      "2 1900-01-01 12:37:06.206  103.732414     0\n",
      "3 1900-01-01 12:37:06.216  101.779229     0\n",
      "4 1900-01-01 12:37:06.226  100.894192     0\n"
     ]
    }
   ],
   "source": [
    "for index, row in datatimeOA.iterrows():\n",
    "    mask = (flowData['time'] >= row['StartDate']) & (flowData['time'] <= row['endDate'])\n",
    "    flowData.loc[mask, 'nhan'] = 1\n",
    "    \n",
    "\n",
    "print(flowData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           time      value  nhan\n",
      "35983   1900-01-01 12:43:06.006  57.924131     1\n",
      "35984   1900-01-01 12:43:06.016  58.473464     1\n",
      "35985   1900-01-01 12:43:06.026  58.809168     1\n",
      "35986   1900-01-01 12:43:06.036  58.992279     1\n",
      "35987   1900-01-01 12:43:06.046  58.992279     1\n",
      "...                         ...        ...   ...\n",
      "1048570 1900-01-01 03:31:51.606  55.543687     1\n",
      "1048571 1900-01-01 03:31:51.616  54.780725     1\n",
      "1048572 1900-01-01 03:31:51.626  54.780725     1\n",
      "1048573 1900-01-01 03:31:51.636  54.780725     1\n",
      "1048574 1900-01-01 03:31:51.646  55.299539     1\n",
      "\n",
      "[629144 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "flowData_nhan_1 = flowData[flowData['nhan'] == 1]\n",
    "print(flowData_nhan_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_training_data(data, window_size, step_size):\n",
    "\n",
    "    _train = []\n",
    "    _label = []\n",
    "\n",
    "    for i in range(0, data.shape[0] - window_size, step_size):\n",
    "        try:\n",
    "            xs = data['value'].values[i: i + window_size]\n",
    "        \n",
    "            # Skip examples where the activity label changes within the window.\n",
    "            if (data['nhan'][i+1] != data['nhan'][i + window_size-1]):\n",
    "                print(f\"Skipping index {i} due to label change within window.\")\n",
    "                continue\n",
    "\n",
    "            label = data['nhan'][i + window_size-1]\n",
    "\n",
    "            # Skip examples where the label is NaN.\n",
    "            if math.isnan(label):\n",
    "                print(f\"Skipping index {i} due to NaN label.\")\n",
    "                continue\n",
    "\n",
    "            _train.append(xs)\n",
    "            _label.append(label)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {i}: {e}\")\n",
    "\n",
    "    return _train, _label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping index 32000 due to label change within window.\n",
      "Skipping index 33000 due to label change within window.\n",
      "Skipping index 36000 due to label change within window.\n",
      "Skipping index 37000 due to label change within window.\n",
      "Skipping index 43000 due to label change within window.\n",
      "Skipping index 44000 due to label change within window.\n",
      "Skipping index 47000 due to label change within window.\n",
      "Skipping index 48000 due to label change within window.\n",
      "Skipping index 53000 due to label change within window.\n",
      "Skipping index 54000 due to label change within window.\n",
      "Skipping index 55000 due to label change within window.\n",
      "Skipping index 56000 due to label change within window.\n",
      "Skipping index 59000 due to label change within window.\n",
      "Skipping index 71000 due to label change within window.\n",
      "Skipping index 72000 due to label change within window.\n",
      "Skipping index 80000 due to label change within window.\n",
      "Skipping index 88000 due to label change within window.\n",
      "Skipping index 89000 due to label change within window.\n",
      "Skipping index 91000 due to label change within window.\n",
      "Skipping index 92000 due to label change within window.\n",
      "Skipping index 93000 due to label change within window.\n",
      "Skipping index 95000 due to label change within window.\n",
      "Skipping index 106000 due to label change within window.\n",
      "Skipping index 110000 due to label change within window.\n",
      "Skipping index 113000 due to label change within window.\n",
      "Skipping index 114000 due to label change within window.\n",
      "Skipping index 115000 due to label change within window.\n",
      "Skipping index 118000 due to label change within window.\n",
      "Skipping index 121000 due to label change within window.\n",
      "Skipping index 123000 due to label change within window.\n",
      "Skipping index 124000 due to label change within window.\n",
      "Skipping index 128000 due to label change within window.\n",
      "Skipping index 131000 due to label change within window.\n",
      "Skipping index 135000 due to label change within window.\n",
      "Skipping index 138000 due to label change within window.\n",
      "Skipping index 140000 due to label change within window.\n",
      "Skipping index 142000 due to label change within window.\n",
      "Skipping index 143000 due to label change within window.\n",
      "Skipping index 146000 due to label change within window.\n",
      "Skipping index 147000 due to label change within window.\n",
      "Skipping index 152000 due to label change within window.\n",
      "Skipping index 154000 due to label change within window.\n",
      "Skipping index 157000 due to label change within window.\n",
      "Skipping index 161000 due to label change within window.\n",
      "Skipping index 162000 due to label change within window.\n",
      "Skipping index 166000 due to label change within window.\n",
      "Skipping index 167000 due to label change within window.\n",
      "Skipping index 171000 due to label change within window.\n",
      "Skipping index 172000 due to label change within window.\n",
      "Skipping index 174000 due to label change within window.\n",
      "Skipping index 175000 due to label change within window.\n",
      "Skipping index 179000 due to label change within window.\n",
      "Skipping index 180000 due to label change within window.\n",
      "Skipping index 184000 due to label change within window.\n",
      "Skipping index 188000 due to label change within window.\n",
      "Skipping index 189000 due to label change within window.\n",
      "Skipping index 190000 due to label change within window.\n",
      "Skipping index 192000 due to label change within window.\n",
      "Skipping index 193000 due to label change within window.\n",
      "Skipping index 200000 due to label change within window.\n",
      "Skipping index 201000 due to label change within window.\n",
      "Skipping index 204000 due to label change within window.\n",
      "Skipping index 211000 due to label change within window.\n",
      "Skipping index 212000 due to label change within window.\n",
      "Skipping index 217000 due to label change within window.\n",
      "Skipping index 219000 due to label change within window.\n",
      "Skipping index 226000 due to label change within window.\n",
      "Skipping index 232000 due to label change within window.\n",
      "Skipping index 234000 due to label change within window.\n",
      "Skipping index 236000 due to label change within window.\n",
      "Skipping index 241000 due to label change within window.\n",
      "Skipping index 245000 due to label change within window.\n",
      "Skipping index 247000 due to label change within window.\n",
      "Skipping index 249000 due to label change within window.\n",
      "Skipping index 253000 due to label change within window.\n",
      "Skipping index 255000 due to label change within window.\n",
      "Skipping index 259000 due to label change within window.\n",
      "Skipping index 262000 due to label change within window.\n",
      "Skipping index 263000 due to label change within window.\n",
      "Skipping index 266000 due to label change within window.\n",
      "Skipping index 267000 due to label change within window.\n",
      "Skipping index 271000 due to label change within window.\n",
      "Skipping index 272000 due to label change within window.\n",
      "Skipping index 275000 due to label change within window.\n",
      "Skipping index 276000 due to label change within window.\n",
      "Skipping index 279000 due to label change within window.\n",
      "Skipping index 280000 due to label change within window.\n",
      "Skipping index 283000 due to label change within window.\n",
      "Skipping index 284000 due to label change within window.\n",
      "Skipping index 287000 due to label change within window.\n",
      "Skipping index 288000 due to label change within window.\n",
      "Skipping index 291000 due to label change within window.\n",
      "Skipping index 295000 due to label change within window.\n",
      "Skipping index 296000 due to label change within window.\n",
      "Skipping index 299000 due to label change within window.\n",
      "Skipping index 300000 due to label change within window.\n",
      "Skipping index 301000 due to label change within window.\n",
      "Skipping index 303000 due to label change within window.\n",
      "Skipping index 304000 due to label change within window.\n",
      "Skipping index 305000 due to label change within window.\n",
      "Skipping index 306000 due to label change within window.\n",
      "Skipping index 308000 due to label change within window.\n",
      "Skipping index 310000 due to label change within window.\n",
      "Skipping index 311000 due to label change within window.\n",
      "Skipping index 313000 due to label change within window.\n",
      "Skipping index 315000 due to label change within window.\n",
      "Skipping index 316000 due to label change within window.\n",
      "Skipping index 317000 due to label change within window.\n",
      "Skipping index 321000 due to label change within window.\n",
      "Skipping index 323000 due to label change within window.\n",
      "Skipping index 324000 due to label change within window.\n",
      "Skipping index 326000 due to label change within window.\n",
      "Skipping index 328000 due to label change within window.\n",
      "Skipping index 330000 due to label change within window.\n",
      "Skipping index 334000 due to label change within window.\n",
      "Skipping index 335000 due to label change within window.\n",
      "Skipping index 336000 due to label change within window.\n",
      "Skipping index 337000 due to label change within window.\n",
      "Skipping index 338000 due to label change within window.\n",
      "Skipping index 340000 due to label change within window.\n",
      "Skipping index 343000 due to label change within window.\n",
      "Skipping index 346000 due to label change within window.\n",
      "Skipping index 347000 due to label change within window.\n",
      "Skipping index 349000 due to label change within window.\n",
      "Skipping index 350000 due to label change within window.\n",
      "Skipping index 351000 due to label change within window.\n",
      "Skipping index 353000 due to label change within window.\n",
      "Skipping index 354000 due to label change within window.\n",
      "Skipping index 355000 due to label change within window.\n",
      "Skipping index 356000 due to label change within window.\n",
      "Skipping index 358000 due to label change within window.\n",
      "Skipping index 359000 due to label change within window.\n",
      "Skipping index 360000 due to label change within window.\n",
      "Skipping index 363000 due to label change within window.\n",
      "Skipping index 364000 due to label change within window.\n",
      "Skipping index 366000 due to label change within window.\n",
      "Skipping index 368000 due to label change within window.\n",
      "Skipping index 369000 due to label change within window.\n",
      "Skipping index 374000 due to label change within window.\n",
      "Skipping index 377000 due to label change within window.\n",
      "Skipping index 378000 due to label change within window.\n",
      "Skipping index 381000 due to label change within window.\n",
      "Skipping index 382000 due to label change within window.\n",
      "Skipping index 388000 due to label change within window.\n",
      "Skipping index 389000 due to label change within window.\n",
      "Skipping index 391000 due to label change within window.\n",
      "Skipping index 392000 due to label change within window.\n",
      "Skipping index 393000 due to label change within window.\n",
      "Skipping index 395000 due to label change within window.\n",
      "Skipping index 396000 due to label change within window.\n",
      "Skipping index 397000 due to label change within window.\n",
      "Skipping index 401000 due to label change within window.\n",
      "Skipping index 402000 due to label change within window.\n",
      "Skipping index 403000 due to label change within window.\n",
      "Skipping index 414000 due to label change within window.\n",
      "Skipping index 415000 due to label change within window.\n",
      "Skipping index 417000 due to label change within window.\n",
      "Skipping index 418000 due to label change within window.\n",
      "Skipping index 420000 due to label change within window.\n",
      "Skipping index 421000 due to label change within window.\n",
      "Skipping index 422000 due to label change within window.\n",
      "Skipping index 424000 due to label change within window.\n",
      "Skipping index 425000 due to label change within window.\n",
      "Skipping index 427000 due to label change within window.\n",
      "Skipping index 428000 due to label change within window.\n",
      "Skipping index 429000 due to label change within window.\n",
      "Skipping index 432000 due to label change within window.\n",
      "Skipping index 434000 due to label change within window.\n",
      "Skipping index 435000 due to label change within window.\n",
      "Skipping index 437000 due to label change within window.\n",
      "Skipping index 438000 due to label change within window.\n",
      "Skipping index 439000 due to label change within window.\n",
      "Skipping index 440000 due to label change within window.\n",
      "Skipping index 442000 due to label change within window.\n",
      "Skipping index 443000 due to label change within window.\n",
      "Skipping index 444000 due to label change within window.\n",
      "Skipping index 446000 due to label change within window.\n",
      "Skipping index 447000 due to label change within window.\n",
      "Skipping index 448000 due to label change within window.\n",
      "Skipping index 450000 due to label change within window.\n",
      "Skipping index 451000 due to label change within window.\n",
      "Skipping index 453000 due to label change within window.\n",
      "Skipping index 454000 due to label change within window.\n",
      "Skipping index 456000 due to label change within window.\n",
      "Skipping index 457000 due to label change within window.\n",
      "Skipping index 459000 due to label change within window.\n",
      "Skipping index 460000 due to label change within window.\n",
      "Skipping index 462000 due to label change within window.\n",
      "Skipping index 463000 due to label change within window.\n",
      "Skipping index 465000 due to label change within window.\n",
      "Skipping index 466000 due to label change within window.\n",
      "Skipping index 468000 due to label change within window.\n",
      "Skipping index 470000 due to label change within window.\n",
      "Skipping index 471000 due to label change within window.\n",
      "Skipping index 479000 due to label change within window.\n",
      "Skipping index 480000 due to label change within window.\n",
      "Skipping index 482000 due to label change within window.\n",
      "Skipping index 484000 due to label change within window.\n",
      "Skipping index 489000 due to label change within window.\n",
      "Skipping index 490000 due to label change within window.\n",
      "Skipping index 492000 due to label change within window.\n",
      "Skipping index 493000 due to label change within window.\n",
      "Skipping index 494000 due to label change within window.\n",
      "Skipping index 496000 due to label change within window.\n",
      "Skipping index 497000 due to label change within window.\n",
      "Skipping index 499000 due to label change within window.\n",
      "Skipping index 500000 due to label change within window.\n",
      "Skipping index 502000 due to label change within window.\n",
      "Skipping index 503000 due to label change within window.\n",
      "Skipping index 506000 due to label change within window.\n",
      "Skipping index 507000 due to label change within window.\n",
      "Skipping index 510000 due to label change within window.\n",
      "Skipping index 515000 due to label change within window.\n",
      "Skipping index 517000 due to label change within window.\n",
      "Skipping index 518000 due to label change within window.\n",
      "Skipping index 520000 due to label change within window.\n",
      "Skipping index 521000 due to label change within window.\n",
      "Skipping index 523000 due to label change within window.\n",
      "Skipping index 524000 due to label change within window.\n",
      "Skipping index 526000 due to label change within window.\n",
      "Skipping index 527000 due to label change within window.\n",
      "Skipping index 529000 due to label change within window.\n",
      "Skipping index 530000 due to label change within window.\n",
      "Skipping index 532000 due to label change within window.\n",
      "Skipping index 537000 due to label change within window.\n",
      "Skipping index 539000 due to label change within window.\n",
      "Skipping index 540000 due to label change within window.\n",
      "Skipping index 545000 due to label change within window.\n",
      "Skipping index 547000 due to label change within window.\n",
      "Skipping index 548000 due to label change within window.\n",
      "Skipping index 549000 due to label change within window.\n",
      "Skipping index 552000 due to label change within window.\n",
      "Skipping index 561000 due to label change within window.\n",
      "Skipping index 564000 due to label change within window.\n",
      "Skipping index 565000 due to label change within window.\n",
      "Skipping index 567000 due to label change within window.\n",
      "Skipping index 568000 due to label change within window.\n",
      "Skipping index 574000 due to label change within window.\n",
      "Skipping index 575000 due to label change within window.\n",
      "Skipping index 576000 due to label change within window.\n",
      "Skipping index 578000 due to label change within window.\n",
      "Skipping index 579000 due to label change within window.\n",
      "Skipping index 580000 due to label change within window.\n",
      "Skipping index 581000 due to label change within window.\n",
      "Skipping index 582000 due to label change within window.\n",
      "Skipping index 583000 due to label change within window.\n",
      "Skipping index 586000 due to label change within window.\n",
      "Skipping index 589000 due to label change within window.\n",
      "Skipping index 591000 due to label change within window.\n",
      "Skipping index 594000 due to label change within window.\n",
      "Skipping index 595000 due to label change within window.\n",
      "Skipping index 597000 due to label change within window.\n",
      "Skipping index 598000 due to label change within window.\n",
      "Skipping index 600000 due to label change within window.\n",
      "Skipping index 601000 due to label change within window.\n",
      "Skipping index 604000 due to label change within window.\n",
      "Skipping index 605000 due to label change within window.\n",
      "Skipping index 606000 due to label change within window.\n",
      "Skipping index 609000 due to label change within window.\n",
      "Skipping index 613000 due to label change within window.\n",
      "Skipping index 614000 due to label change within window.\n",
      "Skipping index 616000 due to label change within window.\n",
      "Skipping index 617000 due to label change within window.\n",
      "Skipping index 620000 due to label change within window.\n",
      "Skipping index 621000 due to label change within window.\n",
      "Skipping index 622000 due to label change within window.\n",
      "Skipping index 624000 due to label change within window.\n",
      "Skipping index 625000 due to label change within window.\n",
      "Skipping index 626000 due to label change within window.\n",
      "Skipping index 627000 due to label change within window.\n",
      "Skipping index 628000 due to label change within window.\n",
      "Skipping index 630000 due to label change within window.\n",
      "Skipping index 631000 due to label change within window.\n",
      "Skipping index 632000 due to label change within window.\n",
      "Skipping index 633000 due to label change within window.\n",
      "Skipping index 634000 due to label change within window.\n",
      "Skipping index 637000 due to label change within window.\n",
      "Skipping index 643000 due to label change within window.\n",
      "Skipping index 644000 due to label change within window.\n",
      "Skipping index 647000 due to label change within window.\n",
      "Skipping index 650000 due to label change within window.\n",
      "Skipping index 653000 due to label change within window.\n",
      "Skipping index 654000 due to label change within window.\n",
      "Skipping index 660000 due to label change within window.\n",
      "Skipping index 661000 due to label change within window.\n",
      "Skipping index 664000 due to label change within window.\n",
      "Skipping index 668000 due to label change within window.\n",
      "Skipping index 671000 due to label change within window.\n",
      "Skipping index 672000 due to label change within window.\n",
      "Skipping index 674000 due to label change within window.\n",
      "Skipping index 678000 due to label change within window.\n",
      "Skipping index 679000 due to label change within window.\n",
      "Skipping index 680000 due to label change within window.\n",
      "Skipping index 681000 due to label change within window.\n",
      "Skipping index 685000 due to label change within window.\n",
      "Skipping index 687000 due to label change within window.\n",
      "Skipping index 688000 due to label change within window.\n",
      "Skipping index 691000 due to label change within window.\n",
      "Skipping index 694000 due to label change within window.\n",
      "Skipping index 695000 due to label change within window.\n",
      "Skipping index 701000 due to label change within window.\n",
      "Skipping index 702000 due to label change within window.\n",
      "Skipping index 703000 due to label change within window.\n",
      "Skipping index 705000 due to label change within window.\n",
      "Skipping index 707000 due to label change within window.\n",
      "Skipping index 708000 due to label change within window.\n",
      "Skipping index 710000 due to label change within window.\n",
      "Skipping index 711000 due to label change within window.\n",
      "Skipping index 712000 due to label change within window.\n",
      "Skipping index 713000 due to label change within window.\n",
      "Skipping index 714000 due to label change within window.\n",
      "Skipping index 717000 due to label change within window.\n",
      "Skipping index 719000 due to label change within window.\n",
      "Skipping index 722000 due to label change within window.\n",
      "Skipping index 723000 due to label change within window.\n",
      "Skipping index 725000 due to label change within window.\n",
      "Skipping index 726000 due to label change within window.\n",
      "Skipping index 727000 due to label change within window.\n",
      "Skipping index 729000 due to label change within window.\n",
      "Skipping index 731000 due to label change within window.\n",
      "Skipping index 734000 due to label change within window.\n",
      "Skipping index 736000 due to label change within window.\n",
      "Skipping index 738000 due to label change within window.\n",
      "Skipping index 740000 due to label change within window.\n",
      "Skipping index 741000 due to label change within window.\n",
      "Skipping index 744000 due to label change within window.\n",
      "Skipping index 749000 due to label change within window.\n",
      "Skipping index 751000 due to label change within window.\n",
      "Skipping index 752000 due to label change within window.\n",
      "Skipping index 754000 due to label change within window.\n",
      "Skipping index 755000 due to label change within window.\n",
      "Skipping index 757000 due to label change within window.\n",
      "Skipping index 758000 due to label change within window.\n",
      "Skipping index 760000 due to label change within window.\n",
      "Skipping index 761000 due to label change within window.\n",
      "Skipping index 762000 due to label change within window.\n",
      "Skipping index 764000 due to label change within window.\n",
      "Skipping index 765000 due to label change within window.\n",
      "Skipping index 766000 due to label change within window.\n",
      "Skipping index 768000 due to label change within window.\n",
      "Skipping index 770000 due to label change within window.\n",
      "Skipping index 771000 due to label change within window.\n",
      "Skipping index 772000 due to label change within window.\n",
      "Skipping index 776000 due to label change within window.\n",
      "Skipping index 778000 due to label change within window.\n",
      "Skipping index 780000 due to label change within window.\n",
      "Skipping index 783000 due to label change within window.\n",
      "Skipping index 784000 due to label change within window.\n",
      "Skipping index 785000 due to label change within window.\n",
      "Skipping index 786000 due to label change within window.\n",
      "Skipping index 787000 due to label change within window.\n",
      "Skipping index 788000 due to label change within window.\n",
      "Skipping index 791000 due to label change within window.\n",
      "Skipping index 793000 due to label change within window.\n",
      "Skipping index 794000 due to label change within window.\n",
      "Skipping index 796000 due to label change within window.\n",
      "Skipping index 797000 due to label change within window.\n",
      "Skipping index 799000 due to label change within window.\n",
      "Skipping index 800000 due to label change within window.\n",
      "Skipping index 807000 due to label change within window.\n",
      "Skipping index 812000 due to label change within window.\n",
      "Skipping index 816000 due to label change within window.\n",
      "Skipping index 818000 due to label change within window.\n",
      "Skipping index 819000 due to label change within window.\n",
      "Skipping index 820000 due to label change within window.\n",
      "Skipping index 821000 due to label change within window.\n",
      "Skipping index 822000 due to label change within window.\n",
      "Skipping index 823000 due to label change within window.\n",
      "Skipping index 828000 due to label change within window.\n",
      "Skipping index 829000 due to label change within window.\n",
      "Skipping index 830000 due to label change within window.\n",
      "Skipping index 833000 due to label change within window.\n",
      "Skipping index 834000 due to label change within window.\n",
      "Skipping index 835000 due to label change within window.\n",
      "Skipping index 837000 due to label change within window.\n",
      "Skipping index 839000 due to label change within window.\n",
      "Skipping index 841000 due to label change within window.\n",
      "Skipping index 842000 due to label change within window.\n",
      "Skipping index 844000 due to label change within window.\n",
      "Skipping index 846000 due to label change within window.\n",
      "Skipping index 847000 due to label change within window.\n",
      "Skipping index 849000 due to label change within window.\n",
      "Skipping index 850000 due to label change within window.\n",
      "Skipping index 851000 due to label change within window.\n",
      "Skipping index 854000 due to label change within window.\n",
      "Skipping index 855000 due to label change within window.\n",
      "Skipping index 856000 due to label change within window.\n",
      "Skipping index 858000 due to label change within window.\n",
      "Skipping index 861000 due to label change within window.\n",
      "Skipping index 862000 due to label change within window.\n",
      "Skipping index 863000 due to label change within window.\n",
      "Skipping index 864000 due to label change within window.\n",
      "Skipping index 865000 due to label change within window.\n",
      "Skipping index 867000 due to label change within window.\n",
      "Skipping index 869000 due to label change within window.\n",
      "Skipping index 870000 due to label change within window.\n",
      "Skipping index 871000 due to label change within window.\n",
      "Skipping index 873000 due to label change within window.\n",
      "Skipping index 874000 due to label change within window.\n",
      "Skipping index 875000 due to label change within window.\n",
      "Skipping index 876000 due to label change within window.\n",
      "Skipping index 877000 due to label change within window.\n",
      "Skipping index 878000 due to label change within window.\n",
      "Skipping index 879000 due to label change within window.\n",
      "Skipping index 880000 due to label change within window.\n",
      "Skipping index 882000 due to label change within window.\n",
      "Skipping index 883000 due to label change within window.\n",
      "Skipping index 884000 due to label change within window.\n",
      "Skipping index 886000 due to label change within window.\n",
      "Skipping index 887000 due to label change within window.\n",
      "Skipping index 890000 due to label change within window.\n",
      "Skipping index 891000 due to label change within window.\n",
      "Skipping index 893000 due to label change within window.\n",
      "Skipping index 894000 due to label change within window.\n",
      "Skipping index 895000 due to label change within window.\n",
      "Skipping index 897000 due to label change within window.\n",
      "Skipping index 898000 due to label change within window.\n",
      "Skipping index 900000 due to label change within window.\n",
      "Skipping index 906000 due to label change within window.\n",
      "Skipping index 908000 due to label change within window.\n",
      "Skipping index 910000 due to label change within window.\n",
      "Skipping index 912000 due to label change within window.\n",
      "Skipping index 913000 due to label change within window.\n",
      "Skipping index 919000 due to label change within window.\n",
      "Skipping index 923000 due to label change within window.\n",
      "Skipping index 925000 due to label change within window.\n",
      "Skipping index 926000 due to label change within window.\n",
      "Skipping index 929000 due to label change within window.\n",
      "Skipping index 932000 due to label change within window.\n",
      "Skipping index 933000 due to label change within window.\n",
      "Skipping index 934000 due to label change within window.\n",
      "Skipping index 936000 due to label change within window.\n",
      "Skipping index 937000 due to label change within window.\n",
      "Skipping index 941000 due to label change within window.\n",
      "Skipping index 945000 due to label change within window.\n",
      "Skipping index 946000 due to label change within window.\n",
      "Skipping index 948000 due to label change within window.\n",
      "Skipping index 953000 due to label change within window.\n",
      "Skipping index 962000 due to label change within window.\n",
      "Skipping index 965000 due to label change within window.\n",
      "Skipping index 966000 due to label change within window.\n",
      "Skipping index 970000 due to label change within window.\n",
      "Skipping index 977000 due to label change within window.\n",
      "Skipping index 978000 due to label change within window.\n",
      "Skipping index 979000 due to label change within window.\n",
      "Skipping index 983000 due to label change within window.\n",
      "Skipping index 984000 due to label change within window.\n",
      "Skipping index 985000 due to label change within window.\n",
      "Skipping index 986000 due to label change within window.\n",
      "Skipping index 987000 due to label change within window.\n",
      "Skipping index 990000 due to label change within window.\n",
      "Skipping index 992000 due to label change within window.\n",
      "Skipping index 999000 due to label change within window.\n",
      "Skipping index 1001000 due to label change within window.\n",
      "Skipping index 1002000 due to label change within window.\n",
      "Skipping index 1004000 due to label change within window.\n",
      "Skipping index 1008000 due to label change within window.\n",
      "Skipping index 1009000 due to label change within window.\n",
      "Skipping index 1010000 due to label change within window.\n",
      "Skipping index 1011000 due to label change within window.\n",
      "Skipping index 1017000 due to label change within window.\n",
      "Skipping index 1019000 due to label change within window.\n",
      "Skipping index 1022000 due to label change within window.\n",
      "Skipping index 1024000 due to label change within window.\n",
      "Skipping index 1025000 due to label change within window.\n",
      "Skipping index 1027000 due to label change within window.\n",
      "Skipping index 1031000 due to label change within window.\n",
      "Skipping index 1032000 due to label change within window.\n",
      "Skipping index 1033000 due to label change within window.\n",
      "Skipping index 1035000 due to label change within window.\n",
      "Skipping index 1037000 due to label change within window.\n",
      "Skipping index 1039000 due to label change within window.\n",
      "Skipping index 1040000 due to label change within window.\n",
      "Skipping index 1041000 due to label change within window.\n",
      "Skipping index 1042000 due to label change within window.\n",
      "Skipping index 1044000 due to label change within window.\n"
     ]
    }
   ],
   "source": [
    "_train, _label = create_training_data(\n",
    "    data=flowData, window_size=4000, step_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1db8dea9a80>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "audio_data = _train[0]\n",
    "\n",
    "audio_data = np.array(audio_data).astype(\"float\")\n",
    "sgram = librosa.stft(audio_data)\n",
    "# librosa.display.specshow(sgram)\n",
    "sgram_mag, _  = librosa.magphase(sgram)\n",
    "mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr =1000)\n",
    "print(mel_scale_sgram.shape)\n",
    "# librosa.display.specshow(mel_scale_sgram)\n",
    "mel_sgram = librosa.amplitude_to_db(mel_scale_sgram , ref=np.min)\n",
    "librosa.display.specshow(mel_sgram ,sr =200, x_axis=\"time\", y_axis=\"mel\")\n",
    "plt.colorbar(format='%+0.2f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import tensorflow\n",
    "def calcuMelSgram(signal):\n",
    "  sgram = librosa.stft(signal)  \n",
    "  sgram_mag, _  = librosa.magphase(sgram)\n",
    "  mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr = 1000)\n",
    "  mel_sgram = librosa.amplitude_to_db(mel_scale_sgram , ref=np.min)\n",
    "  # t = torch.Tensor(mel_sgram)\n",
    "  # t = tensorflow.convert_to_tensor(mel_sgram, dtype=tensorflow.float32)\n",
    "  return mel_sgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMFE = []\n",
    "for i in range(len(_train)):\n",
    "  audio_data = np.array(_train[i]).astype(\"float\")\n",
    "  trainMFE.append(calcuMelSgram(audio_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(trainMFE, _label, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 128, 8)\n",
      "(114, 128, 8)\n",
      "(455, 2)\n",
      "(114, 2)\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x_train_array = np.array(x_train.tolist())\n",
    "\n",
    "x_train_reshaped = x_train_array.reshape(x_train_array.shape[0], 128, 8, 1)\n",
    "\n",
    "x_train_reshaped = x_train_reshaped.astype('float32')\n",
    "\n",
    "\n",
    "x_test_array = np.array(x_test.tolist())\n",
    "\n",
    "x_test_reshaped = x_test_array.reshape(x_test_array.shape[0], 128, 8, 1)\n",
    "\n",
    "x_test_reshaped = x_test_reshaped.astype('float32')\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "print(x_train_array.shape)\n",
    "print(x_test_array.shape)\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)\n",
    "print(y_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 128, 8, 16)        336       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 42, 4, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 42, 4, 16)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 42, 4, 32)         4640      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 20, 2, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 20, 2, 32)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               327936    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333426 (1.27 MB)\n",
      "Trainable params: 333426 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 14ms/step - loss: 4.3670 - accuracy: 0.6132 - val_loss: 0.5214 - val_accuracy: 0.7719\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.7131 - accuracy: 0.5912 - val_loss: 0.5510 - val_accuracy: 0.7193\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.3263 - accuracy: 0.5978 - val_loss: 0.6200 - val_accuracy: 0.6930\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.9053 - accuracy: 0.6308 - val_loss: 0.5855 - val_accuracy: 0.6930\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.6484 - val_loss: 0.6048 - val_accuracy: 0.6930\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.6659 - val_loss: 0.5957 - val_accuracy: 0.6930\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.7051 - accuracy: 0.5956 - val_loss: 0.5911 - val_accuracy: 0.6930\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6901 - val_loss: 0.5864 - val_accuracy: 0.6930\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6052 - accuracy: 0.6879 - val_loss: 0.5821 - val_accuracy: 0.6930\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6681 - val_loss: 0.5776 - val_accuracy: 0.6930\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5883 - accuracy: 0.7077 - val_loss: 0.5727 - val_accuracy: 0.6930\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5915 - accuracy: 0.7011 - val_loss: 0.5703 - val_accuracy: 0.6930\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6076 - accuracy: 0.6769 - val_loss: 0.5700 - val_accuracy: 0.6930\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6117 - accuracy: 0.6857 - val_loss: 0.5709 - val_accuracy: 0.6930\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6549 - val_loss: 0.5732 - val_accuracy: 0.6930\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5689 - accuracy: 0.7231 - val_loss: 0.5729 - val_accuracy: 0.6930\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6901 - val_loss: 0.5701 - val_accuracy: 0.6930\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5991 - accuracy: 0.7055 - val_loss: 0.5728 - val_accuracy: 0.7105\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5910 - accuracy: 0.6813 - val_loss: 0.5725 - val_accuracy: 0.6930\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.7143 - val_loss: 0.5693 - val_accuracy: 0.6930\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5685 - accuracy: 0.7121 - val_loss: 0.5644 - val_accuracy: 0.7018\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5874 - accuracy: 0.6857 - val_loss: 0.5582 - val_accuracy: 0.7105\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.7121 - val_loss: 0.5555 - val_accuracy: 0.7105\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5812 - accuracy: 0.7231 - val_loss: 0.5539 - val_accuracy: 0.7193\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5853 - accuracy: 0.7143 - val_loss: 0.5619 - val_accuracy: 0.7456\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5736 - accuracy: 0.7099 - val_loss: 0.5538 - val_accuracy: 0.7105\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5635 - accuracy: 0.7253 - val_loss: 0.5509 - val_accuracy: 0.7281\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.7275 - val_loss: 0.5481 - val_accuracy: 0.7193\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.7099 - val_loss: 0.5477 - val_accuracy: 0.7193\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5643 - accuracy: 0.7143 - val_loss: 0.5502 - val_accuracy: 0.7193\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5374 - accuracy: 0.7297 - val_loss: 0.5525 - val_accuracy: 0.7105\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.7319 - val_loss: 0.5532 - val_accuracy: 0.7281\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5682 - accuracy: 0.7077 - val_loss: 0.5511 - val_accuracy: 0.7105\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.7275 - val_loss: 0.5524 - val_accuracy: 0.7193\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5597 - accuracy: 0.7385 - val_loss: 0.5543 - val_accuracy: 0.7105\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7121 - val_loss: 0.5576 - val_accuracy: 0.7105\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7231 - val_loss: 0.5503 - val_accuracy: 0.7281\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.7341 - val_loss: 0.5499 - val_accuracy: 0.7105\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.7143 - val_loss: 0.5446 - val_accuracy: 0.7544\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5532 - accuracy: 0.7055 - val_loss: 0.5482 - val_accuracy: 0.7105\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7319 - val_loss: 0.5472 - val_accuracy: 0.7544\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5498 - accuracy: 0.7033 - val_loss: 0.5535 - val_accuracy: 0.7105\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.7209 - val_loss: 0.5484 - val_accuracy: 0.7456\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.7319 - val_loss: 0.5512 - val_accuracy: 0.7105\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7319 - val_loss: 0.5474 - val_accuracy: 0.7105\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7055 - val_loss: 0.5488 - val_accuracy: 0.7456\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.7275 - val_loss: 0.5522 - val_accuracy: 0.7105\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7143 - val_loss: 0.5532 - val_accuracy: 0.7368\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7231 - val_loss: 0.5485 - val_accuracy: 0.7105\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.7495 - val_loss: 0.5449 - val_accuracy: 0.7632\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.7451 - val_loss: 0.5437 - val_accuracy: 0.7281\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5502 - accuracy: 0.7429 - val_loss: 0.5377 - val_accuracy: 0.7544\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5340 - accuracy: 0.7231 - val_loss: 0.5352 - val_accuracy: 0.7456\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.7275 - val_loss: 0.5410 - val_accuracy: 0.7368\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5455 - accuracy: 0.7297 - val_loss: 0.5412 - val_accuracy: 0.7456\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7385 - val_loss: 0.5382 - val_accuracy: 0.7544\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5458 - accuracy: 0.7253 - val_loss: 0.5404 - val_accuracy: 0.7544\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.7429 - val_loss: 0.5411 - val_accuracy: 0.7544\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5289 - accuracy: 0.7319 - val_loss: 0.5426 - val_accuracy: 0.7456\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5402 - accuracy: 0.7363 - val_loss: 0.5385 - val_accuracy: 0.7632\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.7473 - val_loss: 0.5466 - val_accuracy: 0.7281\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5537 - accuracy: 0.7429 - val_loss: 0.5433 - val_accuracy: 0.7544\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.7473 - val_loss: 0.5523 - val_accuracy: 0.7193\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5174 - accuracy: 0.7429 - val_loss: 0.5392 - val_accuracy: 0.7456\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.7560 - val_loss: 0.5379 - val_accuracy: 0.7632\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7385 - val_loss: 0.5361 - val_accuracy: 0.7544\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5401 - accuracy: 0.7451 - val_loss: 0.5464 - val_accuracy: 0.7368\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7670 - val_loss: 0.5337 - val_accuracy: 0.7632\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5237 - accuracy: 0.7582 - val_loss: 0.5360 - val_accuracy: 0.7456\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5158 - accuracy: 0.7495 - val_loss: 0.5401 - val_accuracy: 0.7368\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5252 - accuracy: 0.7473 - val_loss: 0.5419 - val_accuracy: 0.7368\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5280 - accuracy: 0.7341 - val_loss: 0.5351 - val_accuracy: 0.7456\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5221 - accuracy: 0.7451 - val_loss: 0.5327 - val_accuracy: 0.7368\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5081 - accuracy: 0.7560 - val_loss: 0.5365 - val_accuracy: 0.7368\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.7429 - val_loss: 0.5284 - val_accuracy: 0.7544\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5407 - accuracy: 0.7297 - val_loss: 0.5337 - val_accuracy: 0.7368\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.7495 - val_loss: 0.5372 - val_accuracy: 0.7719\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5439 - accuracy: 0.7319 - val_loss: 0.5515 - val_accuracy: 0.7105\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.7341 - val_loss: 0.5337 - val_accuracy: 0.7719\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.7560 - val_loss: 0.5534 - val_accuracy: 0.7105\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7538 - val_loss: 0.5430 - val_accuracy: 0.7456\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5187 - accuracy: 0.7516 - val_loss: 0.5465 - val_accuracy: 0.7105\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.7451 - val_loss: 0.5396 - val_accuracy: 0.7632\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5273 - accuracy: 0.7429 - val_loss: 0.5416 - val_accuracy: 0.7368\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5338 - accuracy: 0.7407 - val_loss: 0.5327 - val_accuracy: 0.7456\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7758 - val_loss: 0.5321 - val_accuracy: 0.7368\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.7582 - val_loss: 0.5276 - val_accuracy: 0.7632\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5145 - accuracy: 0.7626 - val_loss: 0.5323 - val_accuracy: 0.7456\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5337 - accuracy: 0.7538 - val_loss: 0.5415 - val_accuracy: 0.7368\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.7604 - val_loss: 0.5303 - val_accuracy: 0.7632\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.7648 - val_loss: 0.5334 - val_accuracy: 0.7456\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.7451 - val_loss: 0.5271 - val_accuracy: 0.7719\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.7824 - val_loss: 0.5394 - val_accuracy: 0.7632\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.7473 - val_loss: 0.5285 - val_accuracy: 0.7719\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7670 - val_loss: 0.5328 - val_accuracy: 0.7456\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.7692 - val_loss: 0.5306 - val_accuracy: 0.7544\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.7692 - val_loss: 0.5339 - val_accuracy: 0.7719\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7473 - val_loss: 0.5416 - val_accuracy: 0.7456\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.7582 - val_loss: 0.5307 - val_accuracy: 0.7456\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.7648 - val_loss: 0.5407 - val_accuracy: 0.7456\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.7560 - val_loss: 0.5352 - val_accuracy: 0.7719\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.7582 - val_loss: 0.5342 - val_accuracy: 0.7632\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.7714 - val_loss: 0.5289 - val_accuracy: 0.7544\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5325 - accuracy: 0.7473 - val_loss: 0.5332 - val_accuracy: 0.7368\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.7626 - val_loss: 0.5304 - val_accuracy: 0.7456\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.7648 - val_loss: 0.5298 - val_accuracy: 0.7456\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4907 - accuracy: 0.7626 - val_loss: 0.5355 - val_accuracy: 0.7544\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.7670 - val_loss: 0.5356 - val_accuracy: 0.7193\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.7692 - val_loss: 0.5267 - val_accuracy: 0.7456\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.7692 - val_loss: 0.5432 - val_accuracy: 0.7368\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.7473 - val_loss: 0.5247 - val_accuracy: 0.7544\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.7780 - val_loss: 0.5269 - val_accuracy: 0.7456\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5048 - accuracy: 0.7604 - val_loss: 0.5339 - val_accuracy: 0.7281\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.7582 - val_loss: 0.5328 - val_accuracy: 0.7281\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.7714 - val_loss: 0.5261 - val_accuracy: 0.7719\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.7890 - val_loss: 0.5211 - val_accuracy: 0.7632\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7719\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.7824 - val_loss: 0.5288 - val_accuracy: 0.7632\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.7714 - val_loss: 0.5311 - val_accuracy: 0.7368\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.7780 - val_loss: 0.5391 - val_accuracy: 0.7368\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.7692 - val_loss: 0.5236 - val_accuracy: 0.7719\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.7560 - val_loss: 0.5366 - val_accuracy: 0.7368\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.7868 - val_loss: 0.5230 - val_accuracy: 0.7719\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7736 - val_loss: 0.5253 - val_accuracy: 0.7719\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.7802 - val_loss: 0.5391 - val_accuracy: 0.7281\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.7473 - val_loss: 0.5255 - val_accuracy: 0.7719\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4723 - accuracy: 0.7934 - val_loss: 0.5314 - val_accuracy: 0.7456\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.7736 - val_loss: 0.5295 - val_accuracy: 0.7281\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.7692 - val_loss: 0.5521 - val_accuracy: 0.7368\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.7670 - val_loss: 0.5440 - val_accuracy: 0.7281\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4559 - accuracy: 0.8066 - val_loss: 0.5286 - val_accuracy: 0.7807\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.7670 - val_loss: 0.5318 - val_accuracy: 0.7807\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.7912 - val_loss: 0.5345 - val_accuracy: 0.7719\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7978 - val_loss: 0.5209 - val_accuracy: 0.7719\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.7692 - val_loss: 0.5416 - val_accuracy: 0.7105\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7802 - val_loss: 0.5147 - val_accuracy: 0.7719\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.7780 - val_loss: 0.5257 - val_accuracy: 0.7456\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.7956 - val_loss: 0.5365 - val_accuracy: 0.7193\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7560 - val_loss: 0.5270 - val_accuracy: 0.7544\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.7582 - val_loss: 0.5368 - val_accuracy: 0.7105\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4816 - accuracy: 0.7714 - val_loss: 0.5211 - val_accuracy: 0.7807\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.7846 - val_loss: 0.5383 - val_accuracy: 0.7719\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.7912 - val_loss: 0.5329 - val_accuracy: 0.7807\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4882 - accuracy: 0.7758 - val_loss: 0.5445 - val_accuracy: 0.7368\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5095 - accuracy: 0.7714 - val_loss: 0.5293 - val_accuracy: 0.7544\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.8000 - val_loss: 0.5461 - val_accuracy: 0.7368\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.7868 - val_loss: 0.5231 - val_accuracy: 0.7719\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.7912 - val_loss: 0.5441 - val_accuracy: 0.7368\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.7736 - val_loss: 0.5361 - val_accuracy: 0.7456\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7846 - val_loss: 0.5172 - val_accuracy: 0.7632\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.8044 - val_loss: 0.5470 - val_accuracy: 0.7368\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7846 - val_loss: 0.5238 - val_accuracy: 0.7368\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7758 - val_loss: 0.5396 - val_accuracy: 0.7193\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4684 - accuracy: 0.7758 - val_loss: 0.5431 - val_accuracy: 0.7281\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.7736 - val_loss: 0.5519 - val_accuracy: 0.7281\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.7912 - val_loss: 0.5516 - val_accuracy: 0.7368\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7890 - val_loss: 0.5530 - val_accuracy: 0.7193\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4661 - accuracy: 0.7780 - val_loss: 0.5257 - val_accuracy: 0.7807\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7802 - val_loss: 0.5603 - val_accuracy: 0.7105\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.7802 - val_loss: 0.5497 - val_accuracy: 0.7193\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.7824 - val_loss: 0.5374 - val_accuracy: 0.7281\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.7692 - val_loss: 0.5434 - val_accuracy: 0.7193\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.7714 - val_loss: 0.5303 - val_accuracy: 0.7456\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.7758 - val_loss: 0.5552 - val_accuracy: 0.7193\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7714 - val_loss: 0.5209 - val_accuracy: 0.7719\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7692 - val_loss: 0.5732 - val_accuracy: 0.7193\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4623 - accuracy: 0.7824 - val_loss: 0.5327 - val_accuracy: 0.7105\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.7495 - val_loss: 0.5585 - val_accuracy: 0.7193\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.7648 - val_loss: 0.5416 - val_accuracy: 0.7193\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.8000 - val_loss: 0.5503 - val_accuracy: 0.7632\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.7868 - val_loss: 0.5671 - val_accuracy: 0.7193\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.7824 - val_loss: 0.5301 - val_accuracy: 0.7632\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.7670 - val_loss: 0.5658 - val_accuracy: 0.7193\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4660 - accuracy: 0.7780 - val_loss: 0.5187 - val_accuracy: 0.7807\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.7780 - val_loss: 0.5394 - val_accuracy: 0.7281\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4450 - accuracy: 0.8176 - val_loss: 0.5182 - val_accuracy: 0.7632\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.7780 - val_loss: 0.5492 - val_accuracy: 0.7105\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.7956 - val_loss: 0.5273 - val_accuracy: 0.7632\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4641 - accuracy: 0.7824 - val_loss: 0.5437 - val_accuracy: 0.7105\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.8066 - val_loss: 0.5258 - val_accuracy: 0.7719\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7780 - val_loss: 0.5684 - val_accuracy: 0.7193\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.7824 - val_loss: 0.5410 - val_accuracy: 0.7632\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.7758 - val_loss: 0.5938 - val_accuracy: 0.7193\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7692 - val_loss: 0.5360 - val_accuracy: 0.7632\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.7604 - val_loss: 0.5808 - val_accuracy: 0.7193\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.7846 - val_loss: 0.5255 - val_accuracy: 0.7719\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.7846 - val_loss: 0.5529 - val_accuracy: 0.7193\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.7890 - val_loss: 0.5198 - val_accuracy: 0.7719\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7978 - val_loss: 0.5232 - val_accuracy: 0.7719\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7780 - val_loss: 0.5567 - val_accuracy: 0.7193\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7846 - val_loss: 0.5393 - val_accuracy: 0.7456\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.8132 - val_loss: 0.5375 - val_accuracy: 0.7807\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.8044 - val_loss: 0.5407 - val_accuracy: 0.7632\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4502 - accuracy: 0.7824 - val_loss: 0.5295 - val_accuracy: 0.7632\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7912 - val_loss: 0.5486 - val_accuracy: 0.7544\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.7868 - val_loss: 0.5598 - val_accuracy: 0.7368\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.7978 - val_loss: 0.5275 - val_accuracy: 0.7632\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8286 - val_loss: 0.5836 - val_accuracy: 0.7281\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4518 - accuracy: 0.8066 - val_loss: 0.5394 - val_accuracy: 0.7632\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.7978 - val_loss: 0.5813 - val_accuracy: 0.7281\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.7934 - val_loss: 0.5294 - val_accuracy: 0.7632\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4470 - accuracy: 0.7890 - val_loss: 0.5773 - val_accuracy: 0.7281\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.7780 - val_loss: 0.5447 - val_accuracy: 0.7632\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7934 - val_loss: 0.5889 - val_accuracy: 0.7456\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.8132 - val_loss: 0.5399 - val_accuracy: 0.7719\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7912 - val_loss: 0.5560 - val_accuracy: 0.7632\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7846 - val_loss: 0.5435 - val_accuracy: 0.7719\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5299 - val_accuracy: 0.7632\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8088 - val_loss: 0.5497 - val_accuracy: 0.7719\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.7692 - val_loss: 0.5583 - val_accuracy: 0.7281\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.7692 - val_loss: 0.5352 - val_accuracy: 0.7544\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4709 - accuracy: 0.7978 - val_loss: 0.5327 - val_accuracy: 0.7719\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8000 - val_loss: 0.5583 - val_accuracy: 0.7544\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5429 - val_accuracy: 0.7719\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.7956 - val_loss: 0.5313 - val_accuracy: 0.7719\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.7736 - val_loss: 0.5484 - val_accuracy: 0.7456\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8154 - val_loss: 0.5458 - val_accuracy: 0.7719\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.8000 - val_loss: 0.5515 - val_accuracy: 0.7719\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.7890 - val_loss: 0.5452 - val_accuracy: 0.7281\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7802 - val_loss: 0.5354 - val_accuracy: 0.7544\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8022 - val_loss: 0.5593 - val_accuracy: 0.7719\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.7912 - val_loss: 0.5264 - val_accuracy: 0.7719\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4458 - accuracy: 0.8088 - val_loss: 0.5410 - val_accuracy: 0.7281\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.5578 - val_accuracy: 0.7456\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4400 - accuracy: 0.7802 - val_loss: 0.5505 - val_accuracy: 0.7544\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8022 - val_loss: 0.5142 - val_accuracy: 0.7632\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7934 - val_loss: 0.5408 - val_accuracy: 0.7281\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.7912 - val_loss: 0.5216 - val_accuracy: 0.7456\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7912 - val_loss: 0.5295 - val_accuracy: 0.7719\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.8154 - val_loss: 0.5391 - val_accuracy: 0.7719\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8308 - val_loss: 0.5873 - val_accuracy: 0.7632\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7956 - val_loss: 0.5443 - val_accuracy: 0.7632\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.8088 - val_loss: 0.5415 - val_accuracy: 0.7719\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8330 - val_loss: 0.5729 - val_accuracy: 0.7719\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.8132 - val_loss: 0.5558 - val_accuracy: 0.7719\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8066 - val_loss: 0.5428 - val_accuracy: 0.7807\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7978 - val_loss: 0.5446 - val_accuracy: 0.7456\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8000 - val_loss: 0.5582 - val_accuracy: 0.7368\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8088 - val_loss: 0.5332 - val_accuracy: 0.7456\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.8154 - val_loss: 0.5504 - val_accuracy: 0.7544\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7978 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4355 - accuracy: 0.7978 - val_loss: 0.5398 - val_accuracy: 0.7719\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8110 - val_loss: 0.5720 - val_accuracy: 0.7368\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8264 - val_loss: 0.5994 - val_accuracy: 0.7719\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8352 - val_loss: 0.5538 - val_accuracy: 0.7719\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8264 - val_loss: 0.5182 - val_accuracy: 0.7544\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.7890 - val_loss: 0.5448 - val_accuracy: 0.7632\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3962 - accuracy: 0.8198 - val_loss: 0.6283 - val_accuracy: 0.7456\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.7956 - val_loss: 0.5486 - val_accuracy: 0.7719\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4442 - accuracy: 0.7956 - val_loss: 0.6031 - val_accuracy: 0.7105\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.7780 - val_loss: 0.6336 - val_accuracy: 0.7368\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8198 - val_loss: 0.5794 - val_accuracy: 0.7807\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8132 - val_loss: 0.5809 - val_accuracy: 0.7456\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8220 - val_loss: 0.5326 - val_accuracy: 0.7719\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8000 - val_loss: 0.5590 - val_accuracy: 0.7281\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8308 - val_loss: 0.5354 - val_accuracy: 0.7632\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8198 - val_loss: 0.5882 - val_accuracy: 0.7456\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8198 - val_loss: 0.6128 - val_accuracy: 0.7368\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5424 - val_accuracy: 0.7632\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4191 - accuracy: 0.7912 - val_loss: 0.5877 - val_accuracy: 0.7544\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3888 - accuracy: 0.8242 - val_loss: 0.6046 - val_accuracy: 0.7456\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8132 - val_loss: 0.5746 - val_accuracy: 0.7719\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8022 - val_loss: 0.5443 - val_accuracy: 0.7719\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5944 - val_accuracy: 0.7368\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.8198 - val_loss: 0.5684 - val_accuracy: 0.7719\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3848 - accuracy: 0.8352 - val_loss: 0.5871 - val_accuracy: 0.7632\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8264 - val_loss: 0.5581 - val_accuracy: 0.7719\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8198 - val_loss: 0.6153 - val_accuracy: 0.7456\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3976 - accuracy: 0.8352 - val_loss: 0.5754 - val_accuracy: 0.7719\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8198 - val_loss: 0.5750 - val_accuracy: 0.7719\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8044 - val_loss: 0.5956 - val_accuracy: 0.7456\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8154 - val_loss: 0.5237 - val_accuracy: 0.7719\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8198 - val_loss: 0.6210 - val_accuracy: 0.7281\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8220 - val_loss: 0.5950 - val_accuracy: 0.7719\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.7978 - val_loss: 0.6437 - val_accuracy: 0.7281\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8044 - val_loss: 0.5535 - val_accuracy: 0.7632\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8022 - val_loss: 0.5658 - val_accuracy: 0.7719\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3753 - accuracy: 0.8176 - val_loss: 0.5449 - val_accuracy: 0.7719\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8066 - val_loss: 0.6030 - val_accuracy: 0.7368\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8110 - val_loss: 0.5446 - val_accuracy: 0.7719\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8264 - val_loss: 0.6420 - val_accuracy: 0.7281\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.8022 - val_loss: 0.6063 - val_accuracy: 0.7719\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8088 - val_loss: 0.5743 - val_accuracy: 0.7807\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8396 - val_loss: 0.5852 - val_accuracy: 0.7719\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8330 - val_loss: 0.5229 - val_accuracy: 0.7632\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8110 - val_loss: 0.5513 - val_accuracy: 0.7544\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8198 - val_loss: 0.5938 - val_accuracy: 0.7544\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8220 - val_loss: 0.5654 - val_accuracy: 0.7719\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.8330 - val_loss: 0.6018 - val_accuracy: 0.7018\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8242 - val_loss: 0.5564 - val_accuracy: 0.7544\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8044 - val_loss: 0.6026 - val_accuracy: 0.7719\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8066 - val_loss: 0.5786 - val_accuracy: 0.7632\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3914 - accuracy: 0.8330 - val_loss: 0.6246 - val_accuracy: 0.7281\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8308 - val_loss: 0.5711 - val_accuracy: 0.7544\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8220 - val_loss: 0.5489 - val_accuracy: 0.7719\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3628 - accuracy: 0.8198 - val_loss: 0.5856 - val_accuracy: 0.7544\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.8462 - val_loss: 0.5902 - val_accuracy: 0.7632\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.8484 - val_loss: 0.5909 - val_accuracy: 0.7544\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.8308 - val_loss: 0.6146 - val_accuracy: 0.7544\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3800 - accuracy: 0.8198 - val_loss: 0.6403 - val_accuracy: 0.7632\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3731 - accuracy: 0.8462 - val_loss: 0.5881 - val_accuracy: 0.7368\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8330 - val_loss: 0.6407 - val_accuracy: 0.7456\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.8352 - val_loss: 0.6273 - val_accuracy: 0.7632\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8418 - val_loss: 0.5945 - val_accuracy: 0.7719\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3382 - accuracy: 0.8418 - val_loss: 0.6404 - val_accuracy: 0.7807\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8396 - val_loss: 0.5843 - val_accuracy: 0.7632\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.8374 - val_loss: 0.6176 - val_accuracy: 0.7368\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8440 - val_loss: 0.5590 - val_accuracy: 0.7719\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.8505 - val_loss: 0.5968 - val_accuracy: 0.7544\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.8396 - val_loss: 0.5565 - val_accuracy: 0.7719\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.8440 - val_loss: 0.6538 - val_accuracy: 0.7456\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3615 - accuracy: 0.8286 - val_loss: 0.5735 - val_accuracy: 0.7719\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3890 - accuracy: 0.8088 - val_loss: 0.5672 - val_accuracy: 0.7632\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.8505 - val_loss: 0.5783 - val_accuracy: 0.7719\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8484 - val_loss: 0.5748 - val_accuracy: 0.7544\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8484 - val_loss: 0.5869 - val_accuracy: 0.7632\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3224 - accuracy: 0.8747 - val_loss: 0.6087 - val_accuracy: 0.7632\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.8484 - val_loss: 0.5638 - val_accuracy: 0.7544\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.8484 - val_loss: 0.6234 - val_accuracy: 0.7456\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3457 - accuracy: 0.8418 - val_loss: 0.6468 - val_accuracy: 0.7719\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.8637 - val_loss: 0.5739 - val_accuracy: 0.7632\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8484 - val_loss: 0.6697 - val_accuracy: 0.7368\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8396 - val_loss: 0.6377 - val_accuracy: 0.7807\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8505 - val_loss: 0.6465 - val_accuracy: 0.7719\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3125 - accuracy: 0.8703 - val_loss: 0.6090 - val_accuracy: 0.7719\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8549 - val_loss: 0.6581 - val_accuracy: 0.7544\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8484 - val_loss: 0.6126 - val_accuracy: 0.7719\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.8681 - val_loss: 0.7018 - val_accuracy: 0.7368\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3320 - accuracy: 0.8396 - val_loss: 0.6010 - val_accuracy: 0.7632\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2992 - accuracy: 0.8791 - val_loss: 0.6221 - val_accuracy: 0.7368\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.8637 - val_loss: 0.6070 - val_accuracy: 0.7544\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8527 - val_loss: 0.6238 - val_accuracy: 0.7632\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3607 - accuracy: 0.8527 - val_loss: 0.6746 - val_accuracy: 0.7544\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3359 - accuracy: 0.8352 - val_loss: 0.5763 - val_accuracy: 0.7544\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3424 - accuracy: 0.8440 - val_loss: 0.6249 - val_accuracy: 0.7544\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.8615 - val_loss: 0.6719 - val_accuracy: 0.7632\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3194 - accuracy: 0.8593 - val_loss: 0.6803 - val_accuracy: 0.7544\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3148 - accuracy: 0.8725 - val_loss: 0.6379 - val_accuracy: 0.7544\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3135 - accuracy: 0.8527 - val_loss: 0.6458 - val_accuracy: 0.7632\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3063 - accuracy: 0.8549 - val_loss: 0.6579 - val_accuracy: 0.7632\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3093 - accuracy: 0.8571 - val_loss: 0.6323 - val_accuracy: 0.7368\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2895 - accuracy: 0.8747 - val_loss: 0.6026 - val_accuracy: 0.7544\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3199 - accuracy: 0.8484 - val_loss: 0.6441 - val_accuracy: 0.7632\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2943 - accuracy: 0.8703 - val_loss: 0.7292 - val_accuracy: 0.7719\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8637 - val_loss: 0.6211 - val_accuracy: 0.7719\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.8549 - val_loss: 0.5819 - val_accuracy: 0.7544\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2582 - accuracy: 0.8879 - val_loss: 0.6382 - val_accuracy: 0.7544\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8505 - val_loss: 0.6102 - val_accuracy: 0.7632\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2951 - accuracy: 0.8637 - val_loss: 0.7173 - val_accuracy: 0.7368\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3110 - accuracy: 0.8440 - val_loss: 0.6461 - val_accuracy: 0.7807\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2865 - accuracy: 0.8637 - val_loss: 0.7034 - val_accuracy: 0.7544\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3041 - accuracy: 0.8681 - val_loss: 0.7422 - val_accuracy: 0.7456\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.8791 - val_loss: 0.6340 - val_accuracy: 0.7719\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2801 - accuracy: 0.8571 - val_loss: 0.6778 - val_accuracy: 0.7632\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.8593 - val_loss: 0.6685 - val_accuracy: 0.7719\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2993 - accuracy: 0.8747 - val_loss: 0.6405 - val_accuracy: 0.7544\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.8703 - val_loss: 0.5988 - val_accuracy: 0.7632\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2979 - accuracy: 0.8813 - val_loss: 0.7169 - val_accuracy: 0.7719\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2713 - accuracy: 0.8681 - val_loss: 0.6877 - val_accuracy: 0.7807\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8857 - val_loss: 0.7291 - val_accuracy: 0.7368\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2541 - accuracy: 0.8901 - val_loss: 0.6615 - val_accuracy: 0.7368\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.8747 - val_loss: 0.6638 - val_accuracy: 0.7456\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.8484 - val_loss: 0.6671 - val_accuracy: 0.7368\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.8857 - val_loss: 0.6603 - val_accuracy: 0.7807\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2763 - accuracy: 0.8725 - val_loss: 0.6938 - val_accuracy: 0.7719\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2969 - accuracy: 0.8637 - val_loss: 0.6851 - val_accuracy: 0.7719\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8593 - val_loss: 0.6673 - val_accuracy: 0.7368\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2988 - accuracy: 0.8747 - val_loss: 0.6558 - val_accuracy: 0.7456\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2960 - accuracy: 0.8725 - val_loss: 0.5588 - val_accuracy: 0.7807\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2873 - accuracy: 0.8879 - val_loss: 0.6538 - val_accuracy: 0.7368\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2655 - accuracy: 0.8791 - val_loss: 0.7196 - val_accuracy: 0.7544\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2822 - accuracy: 0.8769 - val_loss: 0.7379 - val_accuracy: 0.7456\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2490 - accuracy: 0.8923 - val_loss: 0.7514 - val_accuracy: 0.7544\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2544 - accuracy: 0.8967 - val_loss: 0.7135 - val_accuracy: 0.7456\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2549 - accuracy: 0.8835 - val_loss: 0.6987 - val_accuracy: 0.7105\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2492 - accuracy: 0.8989 - val_loss: 0.7391 - val_accuracy: 0.7456\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2134 - accuracy: 0.9209 - val_loss: 0.7739 - val_accuracy: 0.7632\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2845 - accuracy: 0.8747 - val_loss: 0.6398 - val_accuracy: 0.7719\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2892 - accuracy: 0.8791 - val_loss: 0.6754 - val_accuracy: 0.7456\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2585 - accuracy: 0.8879 - val_loss: 0.6858 - val_accuracy: 0.7544\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.8549 - val_loss: 0.7154 - val_accuracy: 0.7368\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2569 - accuracy: 0.9121 - val_loss: 0.7401 - val_accuracy: 0.7632\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2775 - accuracy: 0.8747 - val_loss: 0.6859 - val_accuracy: 0.7368\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2873 - accuracy: 0.8791 - val_loss: 0.6159 - val_accuracy: 0.7544\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2785 - accuracy: 0.8835 - val_loss: 0.7126 - val_accuracy: 0.7719\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2813 - accuracy: 0.8879 - val_loss: 0.8549 - val_accuracy: 0.7544\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2664 - accuracy: 0.8967 - val_loss: 0.6023 - val_accuracy: 0.7368\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2553 - accuracy: 0.9011 - val_loss: 0.6206 - val_accuracy: 0.7544\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8593 - val_loss: 0.7261 - val_accuracy: 0.7456\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2139 - accuracy: 0.9143 - val_loss: 0.6356 - val_accuracy: 0.7456\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2922 - accuracy: 0.8813 - val_loss: 0.7250 - val_accuracy: 0.7281\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.8923 - val_loss: 0.7711 - val_accuracy: 0.7456\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2653 - accuracy: 0.8791 - val_loss: 0.6274 - val_accuracy: 0.7544\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2343 - accuracy: 0.8989 - val_loss: 0.7270 - val_accuracy: 0.7281\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2532 - accuracy: 0.9033 - val_loss: 0.7679 - val_accuracy: 0.7193\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2258 - accuracy: 0.9121 - val_loss: 0.7075 - val_accuracy: 0.7632\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2986 - accuracy: 0.8659 - val_loss: 0.7364 - val_accuracy: 0.7632\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2628 - accuracy: 0.8857 - val_loss: 0.8802 - val_accuracy: 0.7193\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2410 - accuracy: 0.8989 - val_loss: 0.6683 - val_accuracy: 0.7105\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2854 - accuracy: 0.8769 - val_loss: 0.8154 - val_accuracy: 0.7368\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2852 - accuracy: 0.8879 - val_loss: 0.7161 - val_accuracy: 0.7281\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2597 - accuracy: 0.8989 - val_loss: 0.7058 - val_accuracy: 0.7632\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.9165 - val_loss: 0.6753 - val_accuracy: 0.7632\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2351 - accuracy: 0.9209 - val_loss: 0.7918 - val_accuracy: 0.7544\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.9209 - val_loss: 0.7910 - val_accuracy: 0.7368\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2155 - accuracy: 0.9099 - val_loss: 0.7491 - val_accuracy: 0.7544\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2026 - accuracy: 0.9143 - val_loss: 0.7932 - val_accuracy: 0.7544\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2177 - accuracy: 0.9033 - val_loss: 0.8651 - val_accuracy: 0.7632\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2334 - accuracy: 0.9011 - val_loss: 0.7406 - val_accuracy: 0.7632\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2021 - accuracy: 0.9143 - val_loss: 0.7877 - val_accuracy: 0.7193\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2533 - accuracy: 0.8945 - val_loss: 0.7592 - val_accuracy: 0.7632\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2138 - accuracy: 0.8989 - val_loss: 0.7929 - val_accuracy: 0.7368\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2298 - accuracy: 0.9099 - val_loss: 0.7473 - val_accuracy: 0.7632\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2015 - accuracy: 0.9187 - val_loss: 0.8069 - val_accuracy: 0.7368\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.9187 - val_loss: 0.7332 - val_accuracy: 0.7544\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1870 - accuracy: 0.9187 - val_loss: 0.8106 - val_accuracy: 0.7544\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2350 - accuracy: 0.9099 - val_loss: 0.8697 - val_accuracy: 0.7544\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2199 - accuracy: 0.9143 - val_loss: 0.7295 - val_accuracy: 0.7544\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2451 - accuracy: 0.8945 - val_loss: 0.7225 - val_accuracy: 0.7632\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2129 - accuracy: 0.9121 - val_loss: 0.7754 - val_accuracy: 0.7105\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1947 - accuracy: 0.9209 - val_loss: 0.9076 - val_accuracy: 0.7544\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2323 - accuracy: 0.9055 - val_loss: 0.6784 - val_accuracy: 0.7719\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.8835 - val_loss: 0.7933 - val_accuracy: 0.7544\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 0.8072 - val_accuracy: 0.7456\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2363 - accuracy: 0.8923 - val_loss: 0.7754 - val_accuracy: 0.7544\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2016 - accuracy: 0.9209 - val_loss: 0.7529 - val_accuracy: 0.7719\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2519 - accuracy: 0.8923 - val_loss: 0.6403 - val_accuracy: 0.7719\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2398 - accuracy: 0.9011 - val_loss: 0.8159 - val_accuracy: 0.7456\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2120 - accuracy: 0.9231 - val_loss: 0.7607 - val_accuracy: 0.7281\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2135 - accuracy: 0.9077 - val_loss: 0.7756 - val_accuracy: 0.7632\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1971 - accuracy: 0.9253 - val_loss: 0.8748 - val_accuracy: 0.7544\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2134 - accuracy: 0.9209 - val_loss: 0.7458 - val_accuracy: 0.7368\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1995 - accuracy: 0.9077 - val_loss: 0.8290 - val_accuracy: 0.7456\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2061 - accuracy: 0.9231 - val_loss: 0.8076 - val_accuracy: 0.7368\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2037 - accuracy: 0.9143 - val_loss: 0.9011 - val_accuracy: 0.7632\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1754 - accuracy: 0.9253 - val_loss: 0.9720 - val_accuracy: 0.7544\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 0.9077 - val_loss: 0.8188 - val_accuracy: 0.7281\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.9451 - val_loss: 0.7537 - val_accuracy: 0.7632\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1632 - accuracy: 0.9363 - val_loss: 0.8133 - val_accuracy: 0.7632\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.9297 - val_loss: 0.7109 - val_accuracy: 0.7632\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1700 - accuracy: 0.9297 - val_loss: 0.8639 - val_accuracy: 0.7281\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1757 - accuracy: 0.9209 - val_loss: 0.8193 - val_accuracy: 0.7544\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2050 - accuracy: 0.9275 - val_loss: 0.7701 - val_accuracy: 0.7895\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1714 - accuracy: 0.9341 - val_loss: 0.8137 - val_accuracy: 0.7544\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1685 - accuracy: 0.9275 - val_loss: 0.8867 - val_accuracy: 0.7544\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1664 - accuracy: 0.9385 - val_loss: 0.9460 - val_accuracy: 0.7281\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1953 - accuracy: 0.9297 - val_loss: 0.8873 - val_accuracy: 0.7193\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1802 - accuracy: 0.9275 - val_loss: 0.8935 - val_accuracy: 0.7105\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.9429 - val_loss: 0.8579 - val_accuracy: 0.7018\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9165 - val_loss: 0.8199 - val_accuracy: 0.7368\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1516 - accuracy: 0.9407 - val_loss: 0.8695 - val_accuracy: 0.7719\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1553 - accuracy: 0.9451 - val_loss: 0.8974 - val_accuracy: 0.7193\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1665 - accuracy: 0.9429 - val_loss: 0.7491 - val_accuracy: 0.7368\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2022 - accuracy: 0.9407 - val_loss: 0.7213 - val_accuracy: 0.7632\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1449 - accuracy: 0.9516 - val_loss: 0.9670 - val_accuracy: 0.7368\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1704 - accuracy: 0.9341 - val_loss: 0.9451 - val_accuracy: 0.7368\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1563 - accuracy: 0.9451 - val_loss: 0.7698 - val_accuracy: 0.7456\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.9429 - val_loss: 0.8487 - val_accuracy: 0.7544\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1754 - accuracy: 0.9209 - val_loss: 0.9542 - val_accuracy: 0.7456\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1559 - accuracy: 0.9341 - val_loss: 0.8879 - val_accuracy: 0.7456\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1775 - accuracy: 0.9341 - val_loss: 0.7981 - val_accuracy: 0.7105\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.9121 - val_loss: 0.8555 - val_accuracy: 0.7281\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9363 - val_loss: 1.0444 - val_accuracy: 0.7544\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1640 - accuracy: 0.9319 - val_loss: 0.7616 - val_accuracy: 0.7544\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1851 - accuracy: 0.9253 - val_loss: 0.7316 - val_accuracy: 0.7544\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1459 - accuracy: 0.9363 - val_loss: 0.8711 - val_accuracy: 0.7018\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 0.9363 - val_loss: 0.8914 - val_accuracy: 0.7281\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1284 - accuracy: 0.9473 - val_loss: 0.9096 - val_accuracy: 0.7544\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2070 - accuracy: 0.9341 - val_loss: 0.8423 - val_accuracy: 0.7368\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9319 - val_loss: 0.8849 - val_accuracy: 0.7456\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.9473 - val_loss: 0.7969 - val_accuracy: 0.7544\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1289 - accuracy: 0.9538 - val_loss: 0.8060 - val_accuracy: 0.7368\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1389 - accuracy: 0.9516 - val_loss: 0.8972 - val_accuracy: 0.7368\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1214 - accuracy: 0.9538 - val_loss: 0.9053 - val_accuracy: 0.7544\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9209 - val_loss: 0.9658 - val_accuracy: 0.7544\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 0.9407 - val_loss: 0.8573 - val_accuracy: 0.7193\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1723 - accuracy: 0.9341 - val_loss: 1.0145 - val_accuracy: 0.7456\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9407 - val_loss: 0.8197 - val_accuracy: 0.7456\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1393 - accuracy: 0.9495 - val_loss: 0.9139 - val_accuracy: 0.7632\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.9319 - val_loss: 0.7585 - val_accuracy: 0.7368\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1822 - accuracy: 0.9319 - val_loss: 0.9930 - val_accuracy: 0.7632\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9407 - val_loss: 0.9498 - val_accuracy: 0.7632\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.9319 - val_loss: 0.9018 - val_accuracy: 0.7368\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.9516 - val_loss: 0.8893 - val_accuracy: 0.7544\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9516 - val_loss: 0.9430 - val_accuracy: 0.7632\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9451 - val_loss: 0.9065 - val_accuracy: 0.7632\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1553 - accuracy: 0.9429 - val_loss: 1.0540 - val_accuracy: 0.7544\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.9429 - val_loss: 1.0012 - val_accuracy: 0.7281\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.9495 - val_loss: 0.9702 - val_accuracy: 0.7368\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1089 - accuracy: 0.9582 - val_loss: 0.8280 - val_accuracy: 0.7719\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1365 - accuracy: 0.9385 - val_loss: 0.7935 - val_accuracy: 0.7544\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1788 - accuracy: 0.9407 - val_loss: 0.9396 - val_accuracy: 0.7456\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9626 - val_loss: 0.8974 - val_accuracy: 0.7632\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.9385 - val_loss: 0.9655 - val_accuracy: 0.7018\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1956 - accuracy: 0.9033 - val_loss: 1.0674 - val_accuracy: 0.7281\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1325 - accuracy: 0.9560 - val_loss: 0.7780 - val_accuracy: 0.7719\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.9275 - val_loss: 0.7682 - val_accuracy: 0.7456\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.9429 - val_loss: 0.8568 - val_accuracy: 0.7193\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.9582 - val_loss: 1.0227 - val_accuracy: 0.7456\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1374 - accuracy: 0.9407 - val_loss: 0.8876 - val_accuracy: 0.7456\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.7456\n",
      "Test accuracy: 0.7456140518188477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x_train_tf = np.array([data.reshape(-1, 128, 87, 1) for data in train_df[\"acoustic_data\"]])\n",
    "\n",
    "# x_test_tf = np.array([data.reshape(-1, 128, 87, 1) for data in test_df[\"acoustic_data\"]])\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,4),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (128,8,1)))\n",
    "model.add(MaxPool2D(pool_size=(3,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005, beta_1=0.95, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# In tóm tắt mô hình\n",
    "model.summary()\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(x_train_reshaped, y_train_encoded, epochs=500, validation_data=(x_test_reshaped, y_test_encoded))\n",
    "\n",
    "# Đánh giá mô hình\n",
    "test_loss, test_acc = model.evaluate(x_test_reshaped, y_test_encoded)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
